{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04371d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed libraries\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import statsmodels\n",
    "import keras\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd862ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\jonat\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.58.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4507f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-datareader in c:\\users\\jonat\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from pandas-datareader) (4.9.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from pandas-datareader) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from pandas-datareader) (2.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from pandas>=0.23->pandas-datareader) (1.24.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pandas-datareader) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jonat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.23->pandas-datareader) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13d3a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps to build a ML model \n",
    "# 1. problem defination\n",
    "# 2. loading packages\n",
    "# 3. exploratiry data analysis -> visualization, stats\n",
    "# 4. data preparation -> data cleaning, feature selection, data transformation \n",
    "# 5. evaluate models -> train-test split, identify evaluation metrics, model comparison\n",
    "# 6. model tuning and enhancement -> #grid search\n",
    "# 7. finaliza model -> performance on test data, model / variable intuition, save/deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a68d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection Process:\n",
    "    # 1. Simplicity\n",
    "    # 2. Training Time\n",
    "    # 3. Handling Non-Linearity\n",
    "    # 4. Robustness to overfitting\n",
    "    # 5. Dataset size\n",
    "    # 6. Number of features \n",
    "    # 7. Model Interpretation\n",
    "    # 8. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be8ca4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1:\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pandas_datareader.data as web\n",
    "import datetime as dt\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import statsmodels\n",
    "import keras\n",
    "import tensorflow\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#save model using pickle\n",
    "from pickle import dump\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2093dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  5 of 5 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Adj Close</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Open</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>...</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>40.776520</td>\n",
       "      <td>59.450500</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>80.391838</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>43.064999</td>\n",
       "      <td>59.450500</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>85.949997</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>...</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>58.599998</td>\n",
       "      <td>52.417000</td>\n",
       "      <td>86.129997</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>102223600</td>\n",
       "      <td>53890000</td>\n",
       "      <td>24752000</td>\n",
       "      <td>22483800</td>\n",
       "      <td>65283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>40.769424</td>\n",
       "      <td>60.209999</td>\n",
       "      <td>54.124001</td>\n",
       "      <td>80.765961</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>43.057499</td>\n",
       "      <td>60.209999</td>\n",
       "      <td>54.124001</td>\n",
       "      <td>86.349998</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.132500</td>\n",
       "      <td>59.415001</td>\n",
       "      <td>53.215500</td>\n",
       "      <td>86.059998</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>118071600</td>\n",
       "      <td>62176000</td>\n",
       "      <td>28604000</td>\n",
       "      <td>26061400</td>\n",
       "      <td>67822500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>40.958797</td>\n",
       "      <td>60.479500</td>\n",
       "      <td>54.320000</td>\n",
       "      <td>81.476845</td>\n",
       "      <td>20.974667</td>\n",
       "      <td>43.257500</td>\n",
       "      <td>60.479500</td>\n",
       "      <td>54.320000</td>\n",
       "      <td>87.110001</td>\n",
       "      <td>20.974667</td>\n",
       "      <td>...</td>\n",
       "      <td>43.134998</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>54.400002</td>\n",
       "      <td>86.589996</td>\n",
       "      <td>20.858000</td>\n",
       "      <td>89738400</td>\n",
       "      <td>60442000</td>\n",
       "      <td>20092000</td>\n",
       "      <td>21912000</td>\n",
       "      <td>149194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>41.425129</td>\n",
       "      <td>61.457001</td>\n",
       "      <td>55.111500</td>\n",
       "      <td>82.486992</td>\n",
       "      <td>21.105333</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>61.457001</td>\n",
       "      <td>55.111500</td>\n",
       "      <td>88.190002</td>\n",
       "      <td>21.105333</td>\n",
       "      <td>...</td>\n",
       "      <td>43.360001</td>\n",
       "      <td>60.875500</td>\n",
       "      <td>54.700001</td>\n",
       "      <td>87.660004</td>\n",
       "      <td>21.108000</td>\n",
       "      <td>94640000</td>\n",
       "      <td>70894000</td>\n",
       "      <td>25582000</td>\n",
       "      <td>23407100</td>\n",
       "      <td>68868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>41.271267</td>\n",
       "      <td>62.343498</td>\n",
       "      <td>55.347000</td>\n",
       "      <td>82.571175</td>\n",
       "      <td>22.427334</td>\n",
       "      <td>43.587502</td>\n",
       "      <td>62.343498</td>\n",
       "      <td>55.347000</td>\n",
       "      <td>88.279999</td>\n",
       "      <td>22.427334</td>\n",
       "      <td>...</td>\n",
       "      <td>43.587502</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>55.111500</td>\n",
       "      <td>88.199997</td>\n",
       "      <td>21.066668</td>\n",
       "      <td>82271200</td>\n",
       "      <td>85590000</td>\n",
       "      <td>20952000</td>\n",
       "      <td>22113000</td>\n",
       "      <td>147891000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj Close                                                  Close  \\\n",
       "                 AAPL       AMZN       GOOG       MSFT       TSLA       AAPL   \n",
       "Date                                                                           \n",
       "2018-01-02  40.776520  59.450500  53.250000  80.391838  21.368668  43.064999   \n",
       "2018-01-03  40.769424  60.209999  54.124001  80.765961  21.150000  43.057499   \n",
       "2018-01-04  40.958797  60.479500  54.320000  81.476845  20.974667  43.257500   \n",
       "2018-01-05  41.425129  61.457001  55.111500  82.486992  21.105333  43.750000   \n",
       "2018-01-08  41.271267  62.343498  55.347000  82.571175  22.427334  43.587502   \n",
       "\n",
       "                                                        ...       Open  \\\n",
       "                 AMZN       GOOG       MSFT       TSLA  ...       AAPL   \n",
       "Date                                                    ...              \n",
       "2018-01-02  59.450500  53.250000  85.949997  21.368668  ...  42.540001   \n",
       "2018-01-03  60.209999  54.124001  86.349998  21.150000  ...  43.132500   \n",
       "2018-01-04  60.479500  54.320000  87.110001  20.974667  ...  43.134998   \n",
       "2018-01-05  61.457001  55.111500  88.190002  21.105333  ...  43.360001   \n",
       "2018-01-08  62.343498  55.347000  88.279999  22.427334  ...  43.587502   \n",
       "\n",
       "                                                           Volume            \\\n",
       "                 AMZN       GOOG       MSFT       TSLA       AAPL      AMZN   \n",
       "Date                                                                          \n",
       "2018-01-02  58.599998  52.417000  86.129997  20.799999  102223600  53890000   \n",
       "2018-01-03  59.415001  53.215500  86.059998  21.400000  118071600  62176000   \n",
       "2018-01-04  60.250000  54.400002  86.589996  20.858000   89738400  60442000   \n",
       "2018-01-05  60.875500  54.700001  87.660004  21.108000   94640000  70894000   \n",
       "2018-01-08  61.799999  55.111500  88.199997  21.066668   82271200  85590000   \n",
       "\n",
       "                                           \n",
       "                GOOG      MSFT       TSLA  \n",
       "Date                                       \n",
       "2018-01-02  24752000  22483800   65283000  \n",
       "2018-01-03  28604000  26061400   67822500  \n",
       "2018-01-04  20092000  21912000  149194500  \n",
       "2018-01-05  25582000  23407100   68868000  \n",
       "2018-01-08  20952000  22113000  147891000  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting my data\n",
    "start = dt.datetime(2018,1,2)\n",
    "end = dt.datetime(2022,12,29)\n",
    "\n",
    "stk_tickers = ['AAPL','MSFT','AMZN','TSLA','GOOG']\n",
    "ccy_tickers = ['DEXJPUS','DEXUSUK']\n",
    "idx_tickers = ['SP500','DJIA','VIXCLS']\n",
    "\n",
    "yf.pdr_override()\n",
    "stk_data = yf.download(stk_tickers,start,end)\n",
    "ccy_data = web.get_data_fred(ccy_tickers,start,end)\n",
    "idx_data = web.get_data_fred(idx_tickers,start,end)\n",
    "\n",
    "stk_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae8ddeee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Adj Close</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>9.635211e+01</td>\n",
       "      <td>4.649583e+01</td>\n",
       "      <td>3.416383e+01</td>\n",
       "      <td>4.929744e+01</td>\n",
       "      <td>8.942937e+01</td>\n",
       "      <td>1.415702e+02</td>\n",
       "      <td>1.801910e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.198692e+02</td>\n",
       "      <td>3.559179e+01</td>\n",
       "      <td>5.945050e+01</td>\n",
       "      <td>8.899950e+01</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.581005e+02</td>\n",
       "      <td>1.865705e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>8.596194e+01</td>\n",
       "      <td>3.126965e+01</td>\n",
       "      <td>4.881100e+01</td>\n",
       "      <td>5.841950e+01</td>\n",
       "      <td>7.372250e+01</td>\n",
       "      <td>1.133635e+02</td>\n",
       "      <td>1.507090e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.887661e+02</td>\n",
       "      <td>7.505658e+01</td>\n",
       "      <td>7.951265e+01</td>\n",
       "      <td>1.140590e+02</td>\n",
       "      <td>1.954478e+02</td>\n",
       "      <td>2.515304e+02</td>\n",
       "      <td>3.376211e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.317997e+02</td>\n",
       "      <td>1.179290e+02</td>\n",
       "      <td>1.193133e+01</td>\n",
       "      <td>2.107533e+01</td>\n",
       "      <td>7.464200e+01</td>\n",
       "      <td>2.361633e+02</td>\n",
       "      <td>4.099700e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Close</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>9.804250e+01</td>\n",
       "      <td>4.632948e+01</td>\n",
       "      <td>3.554750e+01</td>\n",
       "      <td>5.100500e+01</td>\n",
       "      <td>9.121000e+01</td>\n",
       "      <td>1.429000e+02</td>\n",
       "      <td>1.820100e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.198692e+02</td>\n",
       "      <td>3.559179e+01</td>\n",
       "      <td>5.945050e+01</td>\n",
       "      <td>8.899950e+01</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.581005e+02</td>\n",
       "      <td>1.865705e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>8.596194e+01</td>\n",
       "      <td>3.126965e+01</td>\n",
       "      <td>4.881100e+01</td>\n",
       "      <td>5.841950e+01</td>\n",
       "      <td>7.372250e+01</td>\n",
       "      <td>1.133635e+02</td>\n",
       "      <td>1.507090e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.937994e+02</td>\n",
       "      <td>7.464854e+01</td>\n",
       "      <td>8.501000e+01</td>\n",
       "      <td>1.193600e+02</td>\n",
       "      <td>2.013000e+02</td>\n",
       "      <td>2.553500e+02</td>\n",
       "      <td>3.431100e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.317997e+02</td>\n",
       "      <td>1.179290e+02</td>\n",
       "      <td>1.193133e+01</td>\n",
       "      <td>2.107533e+01</td>\n",
       "      <td>7.464200e+01</td>\n",
       "      <td>2.361633e+02</td>\n",
       "      <td>4.099700e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">High</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>9.916848e+01</td>\n",
       "      <td>4.691575e+01</td>\n",
       "      <td>3.643000e+01</td>\n",
       "      <td>5.143000e+01</td>\n",
       "      <td>9.261750e+01</td>\n",
       "      <td>1.445000e+02</td>\n",
       "      <td>1.829400e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.213915e+02</td>\n",
       "      <td>3.603749e+01</td>\n",
       "      <td>5.950000e+01</td>\n",
       "      <td>8.978250e+01</td>\n",
       "      <td>1.107805e+02</td>\n",
       "      <td>1.599375e+02</td>\n",
       "      <td>1.886540e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>8.690094e+01</td>\n",
       "      <td>3.160843e+01</td>\n",
       "      <td>5.017700e+01</td>\n",
       "      <td>5.892225e+01</td>\n",
       "      <td>7.441050e+01</td>\n",
       "      <td>1.148100e+02</td>\n",
       "      <td>1.521000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.958064e+02</td>\n",
       "      <td>7.541554e+01</td>\n",
       "      <td>8.631000e+01</td>\n",
       "      <td>1.200200e+02</td>\n",
       "      <td>2.036500e+02</td>\n",
       "      <td>2.591900e+02</td>\n",
       "      <td>3.496700e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.349707e+02</td>\n",
       "      <td>1.207890e+02</td>\n",
       "      <td>1.244533e+01</td>\n",
       "      <td>2.147400e+01</td>\n",
       "      <td>7.568867e+01</td>\n",
       "      <td>2.399967e+02</td>\n",
       "      <td>4.144967e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Low</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>9.683265e+01</td>\n",
       "      <td>4.570808e+01</td>\n",
       "      <td>3.550000e+01</td>\n",
       "      <td>5.056250e+01</td>\n",
       "      <td>9.056750e+01</td>\n",
       "      <td>1.410400e+02</td>\n",
       "      <td>1.791200e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.183413e+02</td>\n",
       "      <td>3.522516e+01</td>\n",
       "      <td>5.852550e+01</td>\n",
       "      <td>8.801100e+01</td>\n",
       "      <td>1.063200e+02</td>\n",
       "      <td>1.562500e+02</td>\n",
       "      <td>1.848395e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>8.501034e+01</td>\n",
       "      <td>3.096076e+01</td>\n",
       "      <td>4.850550e+01</td>\n",
       "      <td>5.787600e+01</td>\n",
       "      <td>7.294950e+01</td>\n",
       "      <td>1.121420e+02</td>\n",
       "      <td>1.498875e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.916085e+02</td>\n",
       "      <td>7.380754e+01</td>\n",
       "      <td>8.383000e+01</td>\n",
       "      <td>1.185200e+02</td>\n",
       "      <td>1.975100e+02</td>\n",
       "      <td>2.529500e+02</td>\n",
       "      <td>3.422000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.285561e+02</td>\n",
       "      <td>1.150650e+02</td>\n",
       "      <td>1.179933e+01</td>\n",
       "      <td>2.064133e+01</td>\n",
       "      <td>7.203333e+01</td>\n",
       "      <td>2.313700e+02</td>\n",
       "      <td>4.056667e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Open</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>9.798050e+01</td>\n",
       "      <td>4.632365e+01</td>\n",
       "      <td>3.599500e+01</td>\n",
       "      <td>5.091250e+01</td>\n",
       "      <td>9.125000e+01</td>\n",
       "      <td>1.427700e+02</td>\n",
       "      <td>1.826300e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.199539e+02</td>\n",
       "      <td>3.565338e+01</td>\n",
       "      <td>5.860000e+01</td>\n",
       "      <td>8.915000e+01</td>\n",
       "      <td>1.081035e+02</td>\n",
       "      <td>1.583500e+02</td>\n",
       "      <td>1.872000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>8.593290e+01</td>\n",
       "      <td>3.130506e+01</td>\n",
       "      <td>4.869500e+01</td>\n",
       "      <td>5.850000e+01</td>\n",
       "      <td>7.351950e+01</td>\n",
       "      <td>1.133035e+02</td>\n",
       "      <td>1.518635e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.937734e+02</td>\n",
       "      <td>7.464738e+01</td>\n",
       "      <td>8.606000e+01</td>\n",
       "      <td>1.193900e+02</td>\n",
       "      <td>2.000500e+02</td>\n",
       "      <td>2.561600e+02</td>\n",
       "      <td>3.446200e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.319332e+02</td>\n",
       "      <td>1.181179e+02</td>\n",
       "      <td>1.207333e+01</td>\n",
       "      <td>2.105333e+01</td>\n",
       "      <td>7.220000e+01</td>\n",
       "      <td>2.356667e+02</td>\n",
       "      <td>4.114700e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Volume</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.169450e+08</td>\n",
       "      <td>5.506465e+07</td>\n",
       "      <td>3.519590e+07</td>\n",
       "      <td>8.023360e+07</td>\n",
       "      <td>1.023496e+08</td>\n",
       "      <td>1.372504e+08</td>\n",
       "      <td>4.265100e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>8.660063e+07</td>\n",
       "      <td>4.069839e+07</td>\n",
       "      <td>1.762600e+07</td>\n",
       "      <td>5.894400e+07</td>\n",
       "      <td>7.505600e+07</td>\n",
       "      <td>1.026240e+08</td>\n",
       "      <td>3.113460e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>3.099530e+07</td>\n",
       "      <td>1.350092e+07</td>\n",
       "      <td>6.936000e+06</td>\n",
       "      <td>2.238200e+07</td>\n",
       "      <td>2.773800e+07</td>\n",
       "      <td>3.531400e+07</td>\n",
       "      <td>1.241400e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>3.023154e+07</td>\n",
       "      <td>1.287752e+07</td>\n",
       "      <td>8.989200e+06</td>\n",
       "      <td>2.217580e+07</td>\n",
       "      <td>2.701000e+07</td>\n",
       "      <td>3.437170e+07</td>\n",
       "      <td>1.112421e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>1257.0</td>\n",
       "      <td>1.323416e+08</td>\n",
       "      <td>9.020984e+07</td>\n",
       "      <td>2.940180e+07</td>\n",
       "      <td>7.577850e+07</td>\n",
       "      <td>1.015584e+08</td>\n",
       "      <td>1.542150e+08</td>\n",
       "      <td>9.140820e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count          mean           std           min  \\\n",
       "Adj Close AAPL  1257.0  9.635211e+01  4.649583e+01  3.416383e+01   \n",
       "          AMZN  1257.0  1.198692e+02  3.559179e+01  5.945050e+01   \n",
       "          GOOG  1257.0  8.596194e+01  3.126965e+01  4.881100e+01   \n",
       "          MSFT  1257.0  1.887661e+02  7.505658e+01  7.951265e+01   \n",
       "          TSLA  1257.0  1.317997e+02  1.179290e+02  1.193133e+01   \n",
       "Close     AAPL  1257.0  9.804250e+01  4.632948e+01  3.554750e+01   \n",
       "          AMZN  1257.0  1.198692e+02  3.559179e+01  5.945050e+01   \n",
       "          GOOG  1257.0  8.596194e+01  3.126965e+01  4.881100e+01   \n",
       "          MSFT  1257.0  1.937994e+02  7.464854e+01  8.501000e+01   \n",
       "          TSLA  1257.0  1.317997e+02  1.179290e+02  1.193133e+01   \n",
       "High      AAPL  1257.0  9.916848e+01  4.691575e+01  3.643000e+01   \n",
       "          AMZN  1257.0  1.213915e+02  3.603749e+01  5.950000e+01   \n",
       "          GOOG  1257.0  8.690094e+01  3.160843e+01  5.017700e+01   \n",
       "          MSFT  1257.0  1.958064e+02  7.541554e+01  8.631000e+01   \n",
       "          TSLA  1257.0  1.349707e+02  1.207890e+02  1.244533e+01   \n",
       "Low       AAPL  1257.0  9.683265e+01  4.570808e+01  3.550000e+01   \n",
       "          AMZN  1257.0  1.183413e+02  3.522516e+01  5.852550e+01   \n",
       "          GOOG  1257.0  8.501034e+01  3.096076e+01  4.850550e+01   \n",
       "          MSFT  1257.0  1.916085e+02  7.380754e+01  8.383000e+01   \n",
       "          TSLA  1257.0  1.285561e+02  1.150650e+02  1.179933e+01   \n",
       "Open      AAPL  1257.0  9.798050e+01  4.632365e+01  3.599500e+01   \n",
       "          AMZN  1257.0  1.199539e+02  3.565338e+01  5.860000e+01   \n",
       "          GOOG  1257.0  8.593290e+01  3.130506e+01  4.869500e+01   \n",
       "          MSFT  1257.0  1.937734e+02  7.464738e+01  8.606000e+01   \n",
       "          TSLA  1257.0  1.319332e+02  1.181179e+02  1.207333e+01   \n",
       "Volume    AAPL  1257.0  1.169450e+08  5.506465e+07  3.519590e+07   \n",
       "          AMZN  1257.0  8.660063e+07  4.069839e+07  1.762600e+07   \n",
       "          GOOG  1257.0  3.099530e+07  1.350092e+07  6.936000e+06   \n",
       "          MSFT  1257.0  3.023154e+07  1.287752e+07  8.989200e+06   \n",
       "          TSLA  1257.0  1.323416e+08  9.020984e+07  2.940180e+07   \n",
       "\n",
       "                         25%           50%           75%           max  \n",
       "Adj Close AAPL  4.929744e+01  8.942937e+01  1.415702e+02  1.801910e+02  \n",
       "          AMZN  8.899950e+01  1.080000e+02  1.581005e+02  1.865705e+02  \n",
       "          GOOG  5.841950e+01  7.372250e+01  1.133635e+02  1.507090e+02  \n",
       "          MSFT  1.140590e+02  1.954478e+02  2.515304e+02  3.376211e+02  \n",
       "          TSLA  2.107533e+01  7.464200e+01  2.361633e+02  4.099700e+02  \n",
       "Close     AAPL  5.100500e+01  9.121000e+01  1.429000e+02  1.820100e+02  \n",
       "          AMZN  8.899950e+01  1.080000e+02  1.581005e+02  1.865705e+02  \n",
       "          GOOG  5.841950e+01  7.372250e+01  1.133635e+02  1.507090e+02  \n",
       "          MSFT  1.193600e+02  2.013000e+02  2.553500e+02  3.431100e+02  \n",
       "          TSLA  2.107533e+01  7.464200e+01  2.361633e+02  4.099700e+02  \n",
       "High      AAPL  5.143000e+01  9.261750e+01  1.445000e+02  1.829400e+02  \n",
       "          AMZN  8.978250e+01  1.107805e+02  1.599375e+02  1.886540e+02  \n",
       "          GOOG  5.892225e+01  7.441050e+01  1.148100e+02  1.521000e+02  \n",
       "          MSFT  1.200200e+02  2.036500e+02  2.591900e+02  3.496700e+02  \n",
       "          TSLA  2.147400e+01  7.568867e+01  2.399967e+02  4.144967e+02  \n",
       "Low       AAPL  5.056250e+01  9.056750e+01  1.410400e+02  1.791200e+02  \n",
       "          AMZN  8.801100e+01  1.063200e+02  1.562500e+02  1.848395e+02  \n",
       "          GOOG  5.787600e+01  7.294950e+01  1.121420e+02  1.498875e+02  \n",
       "          MSFT  1.185200e+02  1.975100e+02  2.529500e+02  3.422000e+02  \n",
       "          TSLA  2.064133e+01  7.203333e+01  2.313700e+02  4.056667e+02  \n",
       "Open      AAPL  5.091250e+01  9.125000e+01  1.427700e+02  1.826300e+02  \n",
       "          AMZN  8.915000e+01  1.081035e+02  1.583500e+02  1.872000e+02  \n",
       "          GOOG  5.850000e+01  7.351950e+01  1.133035e+02  1.518635e+02  \n",
       "          MSFT  1.193900e+02  2.000500e+02  2.561600e+02  3.446200e+02  \n",
       "          TSLA  2.105333e+01  7.220000e+01  2.356667e+02  4.114700e+02  \n",
       "Volume    AAPL  8.023360e+07  1.023496e+08  1.372504e+08  4.265100e+08  \n",
       "          AMZN  5.894400e+07  7.505600e+07  1.026240e+08  3.113460e+08  \n",
       "          GOOG  2.238200e+07  2.773800e+07  3.531400e+07  1.241400e+08  \n",
       "          MSFT  2.217580e+07  2.701000e+07  3.437170e+07  1.112421e+08  \n",
       "          TSLA  7.577850e+07  1.015584e+08  1.542150e+08  9.140820e+08  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4501e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Adj Close</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Close</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Open</th>\n",
       "      <th colspan=\"5\" halign=\"left\">Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>...</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>TSLA</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>TSLA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>40.776520</td>\n",
       "      <td>59.450500</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>80.391838</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>43.064999</td>\n",
       "      <td>59.450500</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>85.949997</td>\n",
       "      <td>21.368668</td>\n",
       "      <td>...</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>58.599998</td>\n",
       "      <td>52.417000</td>\n",
       "      <td>86.129997</td>\n",
       "      <td>20.799999</td>\n",
       "      <td>102223600</td>\n",
       "      <td>53890000</td>\n",
       "      <td>24752000</td>\n",
       "      <td>22483800</td>\n",
       "      <td>65283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>40.769424</td>\n",
       "      <td>60.209999</td>\n",
       "      <td>54.124001</td>\n",
       "      <td>80.765961</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>43.057499</td>\n",
       "      <td>60.209999</td>\n",
       "      <td>54.124001</td>\n",
       "      <td>86.349998</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>...</td>\n",
       "      <td>43.132500</td>\n",
       "      <td>59.415001</td>\n",
       "      <td>53.215500</td>\n",
       "      <td>86.059998</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>118071600</td>\n",
       "      <td>62176000</td>\n",
       "      <td>28604000</td>\n",
       "      <td>26061400</td>\n",
       "      <td>67822500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>40.958797</td>\n",
       "      <td>60.479500</td>\n",
       "      <td>54.320000</td>\n",
       "      <td>81.476845</td>\n",
       "      <td>20.974667</td>\n",
       "      <td>43.257500</td>\n",
       "      <td>60.479500</td>\n",
       "      <td>54.320000</td>\n",
       "      <td>87.110001</td>\n",
       "      <td>20.974667</td>\n",
       "      <td>...</td>\n",
       "      <td>43.134998</td>\n",
       "      <td>60.250000</td>\n",
       "      <td>54.400002</td>\n",
       "      <td>86.589996</td>\n",
       "      <td>20.858000</td>\n",
       "      <td>89738400</td>\n",
       "      <td>60442000</td>\n",
       "      <td>20092000</td>\n",
       "      <td>21912000</td>\n",
       "      <td>149194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>41.425129</td>\n",
       "      <td>61.457001</td>\n",
       "      <td>55.111500</td>\n",
       "      <td>82.486992</td>\n",
       "      <td>21.105333</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>61.457001</td>\n",
       "      <td>55.111500</td>\n",
       "      <td>88.190002</td>\n",
       "      <td>21.105333</td>\n",
       "      <td>...</td>\n",
       "      <td>43.360001</td>\n",
       "      <td>60.875500</td>\n",
       "      <td>54.700001</td>\n",
       "      <td>87.660004</td>\n",
       "      <td>21.108000</td>\n",
       "      <td>94640000</td>\n",
       "      <td>70894000</td>\n",
       "      <td>25582000</td>\n",
       "      <td>23407100</td>\n",
       "      <td>68868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>41.271267</td>\n",
       "      <td>62.343498</td>\n",
       "      <td>55.347000</td>\n",
       "      <td>82.571175</td>\n",
       "      <td>22.427334</td>\n",
       "      <td>43.587502</td>\n",
       "      <td>62.343498</td>\n",
       "      <td>55.347000</td>\n",
       "      <td>88.279999</td>\n",
       "      <td>22.427334</td>\n",
       "      <td>...</td>\n",
       "      <td>43.587502</td>\n",
       "      <td>61.799999</td>\n",
       "      <td>55.111500</td>\n",
       "      <td>88.199997</td>\n",
       "      <td>21.066668</td>\n",
       "      <td>82271200</td>\n",
       "      <td>85590000</td>\n",
       "      <td>20952000</td>\n",
       "      <td>22113000</td>\n",
       "      <td>147891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-21</th>\n",
       "      <td>134.874557</td>\n",
       "      <td>86.769997</td>\n",
       "      <td>90.250000</td>\n",
       "      <td>242.773453</td>\n",
       "      <td>137.570007</td>\n",
       "      <td>135.449997</td>\n",
       "      <td>86.769997</td>\n",
       "      <td>90.250000</td>\n",
       "      <td>244.429993</td>\n",
       "      <td>137.570007</td>\n",
       "      <td>...</td>\n",
       "      <td>132.979996</td>\n",
       "      <td>86.180000</td>\n",
       "      <td>89.730003</td>\n",
       "      <td>241.690002</td>\n",
       "      <td>139.339996</td>\n",
       "      <td>85928000</td>\n",
       "      <td>59267200</td>\n",
       "      <td>20336400</td>\n",
       "      <td>23690600</td>\n",
       "      <td>145417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-22</th>\n",
       "      <td>131.668243</td>\n",
       "      <td>83.790001</td>\n",
       "      <td>88.260002</td>\n",
       "      <td>236.575745</td>\n",
       "      <td>125.349998</td>\n",
       "      <td>132.229996</td>\n",
       "      <td>83.790001</td>\n",
       "      <td>88.260002</td>\n",
       "      <td>238.190002</td>\n",
       "      <td>125.349998</td>\n",
       "      <td>...</td>\n",
       "      <td>134.350006</td>\n",
       "      <td>85.519997</td>\n",
       "      <td>88.930000</td>\n",
       "      <td>241.259995</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>77852100</td>\n",
       "      <td>81431300</td>\n",
       "      <td>23656100</td>\n",
       "      <td>28651700</td>\n",
       "      <td>210090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>131.299820</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>89.809998</td>\n",
       "      <td>237.112091</td>\n",
       "      <td>123.150002</td>\n",
       "      <td>131.860001</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>89.809998</td>\n",
       "      <td>238.729996</td>\n",
       "      <td>123.150002</td>\n",
       "      <td>...</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>83.250000</td>\n",
       "      <td>87.620003</td>\n",
       "      <td>236.110001</td>\n",
       "      <td>126.370003</td>\n",
       "      <td>63814900</td>\n",
       "      <td>57433700</td>\n",
       "      <td>17815000</td>\n",
       "      <td>21207000</td>\n",
       "      <td>166989700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>129.477585</td>\n",
       "      <td>83.040001</td>\n",
       "      <td>87.930000</td>\n",
       "      <td>235.354095</td>\n",
       "      <td>109.099998</td>\n",
       "      <td>130.029999</td>\n",
       "      <td>83.040001</td>\n",
       "      <td>87.930000</td>\n",
       "      <td>236.960007</td>\n",
       "      <td>109.099998</td>\n",
       "      <td>...</td>\n",
       "      <td>131.380005</td>\n",
       "      <td>84.970001</td>\n",
       "      <td>89.309998</td>\n",
       "      <td>238.699997</td>\n",
       "      <td>117.500000</td>\n",
       "      <td>69007800</td>\n",
       "      <td>57284000</td>\n",
       "      <td>15470900</td>\n",
       "      <td>16688600</td>\n",
       "      <td>208643400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>125.504539</td>\n",
       "      <td>81.820000</td>\n",
       "      <td>86.459999</td>\n",
       "      <td>232.940552</td>\n",
       "      <td>112.709999</td>\n",
       "      <td>126.040001</td>\n",
       "      <td>81.820000</td>\n",
       "      <td>86.459999</td>\n",
       "      <td>234.529999</td>\n",
       "      <td>112.709999</td>\n",
       "      <td>...</td>\n",
       "      <td>129.669998</td>\n",
       "      <td>82.800003</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>236.889999</td>\n",
       "      <td>110.349998</td>\n",
       "      <td>85438400</td>\n",
       "      <td>58228600</td>\n",
       "      <td>17879600</td>\n",
       "      <td>17457100</td>\n",
       "      <td>221070500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1257 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close                                                \\\n",
       "                  AAPL       AMZN       GOOG        MSFT        TSLA   \n",
       "Date                                                                   \n",
       "2018-01-02   40.776520  59.450500  53.250000   80.391838   21.368668   \n",
       "2018-01-03   40.769424  60.209999  54.124001   80.765961   21.150000   \n",
       "2018-01-04   40.958797  60.479500  54.320000   81.476845   20.974667   \n",
       "2018-01-05   41.425129  61.457001  55.111500   82.486992   21.105333   \n",
       "2018-01-08   41.271267  62.343498  55.347000   82.571175   22.427334   \n",
       "...                ...        ...        ...         ...         ...   \n",
       "2022-12-21  134.874557  86.769997  90.250000  242.773453  137.570007   \n",
       "2022-12-22  131.668243  83.790001  88.260002  236.575745  125.349998   \n",
       "2022-12-23  131.299820  85.250000  89.809998  237.112091  123.150002   \n",
       "2022-12-27  129.477585  83.040001  87.930000  235.354095  109.099998   \n",
       "2022-12-28  125.504539  81.820000  86.459999  232.940552  112.709999   \n",
       "\n",
       "                 Close                                                ...  \\\n",
       "                  AAPL       AMZN       GOOG        MSFT        TSLA  ...   \n",
       "Date                                                                  ...   \n",
       "2018-01-02   43.064999  59.450500  53.250000   85.949997   21.368668  ...   \n",
       "2018-01-03   43.057499  60.209999  54.124001   86.349998   21.150000  ...   \n",
       "2018-01-04   43.257500  60.479500  54.320000   87.110001   20.974667  ...   \n",
       "2018-01-05   43.750000  61.457001  55.111500   88.190002   21.105333  ...   \n",
       "2018-01-08   43.587502  62.343498  55.347000   88.279999   22.427334  ...   \n",
       "...                ...        ...        ...         ...         ...  ...   \n",
       "2022-12-21  135.449997  86.769997  90.250000  244.429993  137.570007  ...   \n",
       "2022-12-22  132.229996  83.790001  88.260002  238.190002  125.349998  ...   \n",
       "2022-12-23  131.860001  85.250000  89.809998  238.729996  123.150002  ...   \n",
       "2022-12-27  130.029999  83.040001  87.930000  236.960007  109.099998  ...   \n",
       "2022-12-28  126.040001  81.820000  86.459999  234.529999  112.709999  ...   \n",
       "\n",
       "                  Open                                                \\\n",
       "                  AAPL       AMZN       GOOG        MSFT        TSLA   \n",
       "Date                                                                   \n",
       "2018-01-02   42.540001  58.599998  52.417000   86.129997   20.799999   \n",
       "2018-01-03   43.132500  59.415001  53.215500   86.059998   21.400000   \n",
       "2018-01-04   43.134998  60.250000  54.400002   86.589996   20.858000   \n",
       "2018-01-05   43.360001  60.875500  54.700001   87.660004   21.108000   \n",
       "2018-01-08   43.587502  61.799999  55.111500   88.199997   21.066668   \n",
       "...                ...        ...        ...         ...         ...   \n",
       "2022-12-21  132.979996  86.180000  89.730003  241.690002  139.339996   \n",
       "2022-12-22  134.350006  85.519997  88.930000  241.259995  136.000000   \n",
       "2022-12-23  130.919998  83.250000  87.620003  236.110001  126.370003   \n",
       "2022-12-27  131.380005  84.970001  89.309998  238.699997  117.500000   \n",
       "2022-12-28  129.669998  82.800003  87.500000  236.889999  110.349998   \n",
       "\n",
       "               Volume                                           \n",
       "                 AAPL      AMZN      GOOG      MSFT       TSLA  \n",
       "Date                                                            \n",
       "2018-01-02  102223600  53890000  24752000  22483800   65283000  \n",
       "2018-01-03  118071600  62176000  28604000  26061400   67822500  \n",
       "2018-01-04   89738400  60442000  20092000  21912000  149194500  \n",
       "2018-01-05   94640000  70894000  25582000  23407100   68868000  \n",
       "2018-01-08   82271200  85590000  20952000  22113000  147891000  \n",
       "...               ...       ...       ...       ...        ...  \n",
       "2022-12-21   85928000  59267200  20336400  23690600  145417400  \n",
       "2022-12-22   77852100  81431300  23656100  28651700  210090300  \n",
       "2022-12-23   63814900  57433700  17815000  21207000  166989700  \n",
       "2022-12-27   69007800  57284000  15470900  16688600  208643400  \n",
       "2022-12-28   85438400  58228600  17879600  17457100  221070500  \n",
       "\n",
       "[1257 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data-cleaning:\n",
    "# stk_data.isnull().sum()\n",
    "#dropping any 'NA' values within data\n",
    "stk_data.dropna(axis=0) #on the row\n",
    "#or\n",
    "# stk_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca423a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('Adj Close', 'AAPL')_res</th>\n",
       "      <th>('Adj Close', 'AMZN')_res</th>\n",
       "      <th>('Adj Close', 'GOOG')_res</th>\n",
       "      <th>('Adj Close', 'MSFT')_res</th>\n",
       "      <th>('Adj Close', 'TSLA')_res</th>\n",
       "      <th>('Close', 'AAPL')_res</th>\n",
       "      <th>('Close', 'AMZN')_res</th>\n",
       "      <th>('Close', 'GOOG')_res</th>\n",
       "      <th>('Close', 'MSFT')_res</th>\n",
       "      <th>('Close', 'TSLA')_res</th>\n",
       "      <th>...</th>\n",
       "      <th>('Open', 'AAPL')_res</th>\n",
       "      <th>('Open', 'AMZN')_res</th>\n",
       "      <th>('Open', 'GOOG')_res</th>\n",
       "      <th>('Open', 'MSFT')_res</th>\n",
       "      <th>('Open', 'TSLA')_res</th>\n",
       "      <th>('Volume', 'AAPL')_res</th>\n",
       "      <th>('Volume', 'AMZN')_res</th>\n",
       "      <th>('Volume', 'GOOG')_res</th>\n",
       "      <th>('Volume', 'MSFT')_res</th>\n",
       "      <th>('Volume', 'TSLA')_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043563</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.023710</td>\n",
       "      <td>0.051327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043563</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.023710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036077</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.021850</td>\n",
       "      <td>0.171289</td>\n",
       "      <td>0.123465</td>\n",
       "      <td>0.152008</td>\n",
       "      <td>0.131973</td>\n",
       "      <td>0.040558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045235</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.052140</td>\n",
       "      <td>0.004856</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>0.051276</td>\n",
       "      <td>0.005975</td>\n",
       "      <td>0.052140</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048675</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.043817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023352</td>\n",
       "      <td>0.211788</td>\n",
       "      <td>0.151675</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>0.166961</td>\n",
       "      <td>0.043429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.046532</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.054064</td>\n",
       "      <td>0.007610</td>\n",
       "      <td>0.022720</td>\n",
       "      <td>0.052641</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>0.054064</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.022720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048692</td>\n",
       "      <td>0.012830</td>\n",
       "      <td>0.055298</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.021995</td>\n",
       "      <td>0.139383</td>\n",
       "      <td>0.145771</td>\n",
       "      <td>0.112249</td>\n",
       "      <td>0.126381</td>\n",
       "      <td>0.135408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049726</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.061831</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.056004</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.061831</td>\n",
       "      <td>0.012321</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050227</td>\n",
       "      <td>0.017694</td>\n",
       "      <td>0.058206</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>0.022621</td>\n",
       "      <td>0.151909</td>\n",
       "      <td>0.181356</td>\n",
       "      <td>0.159090</td>\n",
       "      <td>0.141002</td>\n",
       "      <td>0.044611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048672</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>0.064143</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>0.026369</td>\n",
       "      <td>0.054895</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>0.064143</td>\n",
       "      <td>0.012669</td>\n",
       "      <td>0.026369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051778</td>\n",
       "      <td>0.024883</td>\n",
       "      <td>0.062194</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>0.022517</td>\n",
       "      <td>0.120301</td>\n",
       "      <td>0.231390</td>\n",
       "      <td>0.119586</td>\n",
       "      <td>0.128346</td>\n",
       "      <td>0.133934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ('Adj Close', 'AAPL')_res  ('Adj Close', 'AMZN')_res  \\\n",
       "0                   0.045284                   0.000000   \n",
       "1                   0.045235                   0.005975   \n",
       "2                   0.046532                   0.008095   \n",
       "3                   0.049726                   0.015784   \n",
       "4                   0.048672                   0.022758   \n",
       "\n",
       "   ('Adj Close', 'GOOG')_res  ('Adj Close', 'MSFT')_res  \\\n",
       "0                   0.043563                   0.003406   \n",
       "1                   0.052140                   0.004856   \n",
       "2                   0.054064                   0.007610   \n",
       "3                   0.061831                   0.011524   \n",
       "4                   0.064143                   0.011850   \n",
       "\n",
       "   ('Adj Close', 'TSLA')_res  ('Close', 'AAPL')_res  ('Close', 'AMZN')_res  \\\n",
       "0                   0.023710               0.051327               0.000000   \n",
       "1                   0.023160               0.051276               0.005975   \n",
       "2                   0.022720               0.052641               0.008095   \n",
       "3                   0.023048               0.056004               0.015784   \n",
       "4                   0.026369               0.054895               0.022758   \n",
       "\n",
       "   ('Close', 'GOOG')_res  ('Close', 'MSFT')_res  ('Close', 'TSLA')_res  ...  \\\n",
       "0               0.043563               0.003642               0.023710  ...   \n",
       "1               0.052140               0.005192               0.023160  ...   \n",
       "2               0.054064               0.008136               0.022720  ...   \n",
       "3               0.061831               0.012321               0.023048  ...   \n",
       "4               0.064143               0.012669               0.026369  ...   \n",
       "\n",
       "   ('Open', 'AAPL')_res  ('Open', 'AMZN')_res  ('Open', 'GOOG')_res  \\\n",
       "0              0.044635              0.000000              0.036077   \n",
       "1              0.048675              0.006337              0.043817   \n",
       "2              0.048692              0.012830              0.055298   \n",
       "3              0.050227              0.017694              0.058206   \n",
       "4              0.051778              0.024883              0.062194   \n",
       "\n",
       "   ('Open', 'MSFT')_res  ('Open', 'TSLA')_res  ('Volume', 'AAPL')_res  \\\n",
       "0              0.000271              0.021850                0.171289   \n",
       "1              0.000000              0.023352                0.211788   \n",
       "2              0.002050              0.021995                0.139383   \n",
       "3              0.006188              0.022621                0.151909   \n",
       "4              0.008277              0.022517                0.120301   \n",
       "\n",
       "   ('Volume', 'AMZN')_res  ('Volume', 'GOOG')_res  ('Volume', 'MSFT')_res  \\\n",
       "0                0.123465                0.152008                0.131973   \n",
       "1                0.151675                0.184874                0.166961   \n",
       "2                0.145771                0.112249                0.126381   \n",
       "3                0.181356                0.159090                0.141002   \n",
       "4                0.231390                0.119586                0.128346   \n",
       "\n",
       "   ('Volume', 'TSLA')_res  \n",
       "0                0.040558  \n",
       "1                0.043429  \n",
       "2                0.135408  \n",
       "3                0.044611  \n",
       "4                0.133934  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Transformation - Rescaling, Standardization, Normalization \n",
    "#Rescaling:\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit and transform the scaler on stk_data\n",
    "rescaled_data = scaler.fit_transform(stk_data)\n",
    "\n",
    "# Create a new DataFrame with the rescaled data\n",
    "rescaledX = pd.DataFrame(rescaled_data, columns=stk_data.columns)\n",
    "\n",
    "# Rename the columns by adding '_res' suffix to each column name\n",
    "rescaledX.columns = [f'{col}_res' for col in rescaledX.columns]\n",
    "\n",
    "# Display the first few rows of the rescaled DataFrame\n",
    "rescaledX.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a50d7b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL_std</th>\n",
       "      <th>AMZN_std</th>\n",
       "      <th>GOOG_std</th>\n",
       "      <th>MSFT_std</th>\n",
       "      <th>TSLA_std</th>\n",
       "      <th>AAPL_std</th>\n",
       "      <th>AMZN_std</th>\n",
       "      <th>GOOG_std</th>\n",
       "      <th>MSFT_std</th>\n",
       "      <th>TSLA_std</th>\n",
       "      <th>...</th>\n",
       "      <th>AAPL_std</th>\n",
       "      <th>AMZN_std</th>\n",
       "      <th>GOOG_std</th>\n",
       "      <th>MSFT_std</th>\n",
       "      <th>TSLA_std</th>\n",
       "      <th>AAPL_std</th>\n",
       "      <th>AMZN_std</th>\n",
       "      <th>GOOG_std</th>\n",
       "      <th>MSFT_std</th>\n",
       "      <th>TSLA_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.195757</td>\n",
       "      <td>-1.698222</td>\n",
       "      <td>-1.046541</td>\n",
       "      <td>-1.444475</td>\n",
       "      <td>-0.936792</td>\n",
       "      <td>-1.187136</td>\n",
       "      <td>-1.698222</td>\n",
       "      <td>-1.046541</td>\n",
       "      <td>-1.445337</td>\n",
       "      <td>-0.936792</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.197284</td>\n",
       "      <td>-1.721528</td>\n",
       "      <td>-1.071049</td>\n",
       "      <td>-1.442600</td>\n",
       "      <td>-0.941241</td>\n",
       "      <td>-0.267455</td>\n",
       "      <td>-0.804053</td>\n",
       "      <td>-0.462620</td>\n",
       "      <td>-0.601888</td>\n",
       "      <td>-0.743659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.195909</td>\n",
       "      <td>-1.676875</td>\n",
       "      <td>-1.018579</td>\n",
       "      <td>-1.439488</td>\n",
       "      <td>-0.938647</td>\n",
       "      <td>-1.187298</td>\n",
       "      <td>-1.676875</td>\n",
       "      <td>-1.018579</td>\n",
       "      <td>-1.439977</td>\n",
       "      <td>-0.938647</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.184488</td>\n",
       "      <td>-1.698660</td>\n",
       "      <td>-1.045531</td>\n",
       "      <td>-1.443538</td>\n",
       "      <td>-0.936159</td>\n",
       "      <td>0.020467</td>\n",
       "      <td>-0.600376</td>\n",
       "      <td>-0.177192</td>\n",
       "      <td>-0.323960</td>\n",
       "      <td>-0.715496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.191835</td>\n",
       "      <td>-1.669300</td>\n",
       "      <td>-1.012309</td>\n",
       "      <td>-1.430013</td>\n",
       "      <td>-0.940135</td>\n",
       "      <td>-1.182979</td>\n",
       "      <td>-1.669300</td>\n",
       "      <td>-1.012309</td>\n",
       "      <td>-1.429792</td>\n",
       "      <td>-0.940135</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.184434</td>\n",
       "      <td>-1.675231</td>\n",
       "      <td>-1.007679</td>\n",
       "      <td>-1.436435</td>\n",
       "      <td>-0.940750</td>\n",
       "      <td>-0.494282</td>\n",
       "      <td>-0.642999</td>\n",
       "      <td>-0.807919</td>\n",
       "      <td>-0.646309</td>\n",
       "      <td>0.186893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.181801</td>\n",
       "      <td>-1.641824</td>\n",
       "      <td>-0.986987</td>\n",
       "      <td>-1.416550</td>\n",
       "      <td>-0.939026</td>\n",
       "      <td>-1.172344</td>\n",
       "      <td>-1.641824</td>\n",
       "      <td>-0.986987</td>\n",
       "      <td>-1.415318</td>\n",
       "      <td>-0.939026</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.179575</td>\n",
       "      <td>-1.657680</td>\n",
       "      <td>-0.998092</td>\n",
       "      <td>-1.422095</td>\n",
       "      <td>-0.938632</td>\n",
       "      <td>-0.405231</td>\n",
       "      <td>-0.386081</td>\n",
       "      <td>-0.401118</td>\n",
       "      <td>-0.530161</td>\n",
       "      <td>-0.703902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.185112</td>\n",
       "      <td>-1.616907</td>\n",
       "      <td>-0.979452</td>\n",
       "      <td>-1.415428</td>\n",
       "      <td>-0.927812</td>\n",
       "      <td>-1.175853</td>\n",
       "      <td>-1.616907</td>\n",
       "      <td>-0.979452</td>\n",
       "      <td>-1.414112</td>\n",
       "      <td>-0.927812</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.174662</td>\n",
       "      <td>-1.631739</td>\n",
       "      <td>-0.984942</td>\n",
       "      <td>-1.414858</td>\n",
       "      <td>-0.938982</td>\n",
       "      <td>-0.629944</td>\n",
       "      <td>-0.024842</td>\n",
       "      <td>-0.744194</td>\n",
       "      <td>-0.630694</td>\n",
       "      <td>0.172437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AAPL_std  AMZN_std  GOOG_std  MSFT_std  TSLA_std  AAPL_std  AMZN_std  \\\n",
       "0 -1.195757 -1.698222 -1.046541 -1.444475 -0.936792 -1.187136 -1.698222   \n",
       "1 -1.195909 -1.676875 -1.018579 -1.439488 -0.938647 -1.187298 -1.676875   \n",
       "2 -1.191835 -1.669300 -1.012309 -1.430013 -0.940135 -1.182979 -1.669300   \n",
       "3 -1.181801 -1.641824 -0.986987 -1.416550 -0.939026 -1.172344 -1.641824   \n",
       "4 -1.185112 -1.616907 -0.979452 -1.415428 -0.927812 -1.175853 -1.616907   \n",
       "\n",
       "   GOOG_std  MSFT_std  TSLA_std  ...  AAPL_std  AMZN_std  GOOG_std  MSFT_std  \\\n",
       "0 -1.046541 -1.445337 -0.936792  ... -1.197284 -1.721528 -1.071049 -1.442600   \n",
       "1 -1.018579 -1.439977 -0.938647  ... -1.184488 -1.698660 -1.045531 -1.443538   \n",
       "2 -1.012309 -1.429792 -0.940135  ... -1.184434 -1.675231 -1.007679 -1.436435   \n",
       "3 -0.986987 -1.415318 -0.939026  ... -1.179575 -1.657680 -0.998092 -1.422095   \n",
       "4 -0.979452 -1.414112 -0.927812  ... -1.174662 -1.631739 -0.984942 -1.414858   \n",
       "\n",
       "   TSLA_std  AAPL_std  AMZN_std  GOOG_std  MSFT_std  TSLA_std  \n",
       "0 -0.941241 -0.267455 -0.804053 -0.462620 -0.601888 -0.743659  \n",
       "1 -0.936159  0.020467 -0.600376 -0.177192 -0.323960 -0.715496  \n",
       "2 -0.940750 -0.494282 -0.642999 -0.807919 -0.646309  0.186893  \n",
       "3 -0.938632 -0.405231 -0.386081 -0.401118 -0.530161 -0.703902  \n",
       "4 -0.938982 -0.629944 -0.024842 -0.744194 -0.630694  0.172437  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardization -> transforms attributes to a standard normal distribution with a mean of zero and a standard deviation 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the StandardScaler and fit it on stk_data\n",
    "scaler = StandardScaler().fit(stk_data)\n",
    "\n",
    "# Transform stk_data using the fitted scaler\n",
    "standardized_data = scaler.transform(stk_data)\n",
    "\n",
    "# Create a new DataFrame with the standardized data\n",
    "StandardisedX = pd.DataFrame(standardized_data, columns=stk_data.columns)\n",
    "\n",
    "# Reset the column index to remove MultiIndex\n",
    "StandardisedX.columns = StandardisedX.columns.droplevel() + '_std'\n",
    "\n",
    "# Display the first few rows of the standardized DataFrame\n",
    "StandardisedX.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b657e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization -> rescaling each observation (row) to have a length of one (called a unit norm or a vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c90f77f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating NN in python\n",
    "# step 1: process the data and split into a training and test set\n",
    "# step 2: build the artificial neural network structure\n",
    "# step 3: train the artificial neural network\n",
    "# step 4: use the model to predict\n",
    "\n",
    "#we first import the dependencies \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Use Pandas to read the CSV file into a DataFrame\n",
    "dataset = pd.read_csv(\"downloads/Churn_Modelling.csv\")\n",
    "\n",
    "# we would want to create input array X and output target array Y\n",
    "# X: we wont to create input vector of useful variables, lets take indewx 3 to 12\n",
    "# Y: Our output will be column 13 - whether they are excited\n",
    "\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "Y = dataset.iloc[:,13].values\n",
    "\n",
    "# We have some columns that are not numerical, like Gender and Geography is slices 1 and 2\n",
    "# We have to change these numerical value for interpretation by ANN. This is called Label Encoding\n",
    "\n",
    "#Geography Column:\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:,1] = labelencoder_X_1.fit_transform(X[:,1])\n",
    "\n",
    "#Gender Column:\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:,2] = labelencoder_X_2.fit_transform(X[:,2])\n",
    "\n",
    "#Splitting dataset to Training Set and Testing Set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size = 0.2, random_state = 0)\n",
    "\n",
    "#Feature Scaling - initializing our ANN inputs for all features to be represented in the same way \n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5f34229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 431us/step - loss: 0.4836 - accuracy: 0.7950\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 416us/step - loss: 0.4339 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 441us/step - loss: 0.4275 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 440us/step - loss: 0.4225 - accuracy: 0.8184\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 438us/step - loss: 0.4206 - accuracy: 0.8253\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 457us/step - loss: 0.4188 - accuracy: 0.8282\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 456us/step - loss: 0.4173 - accuracy: 0.8307\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 460us/step - loss: 0.4166 - accuracy: 0.8309\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 453us/step - loss: 0.4149 - accuracy: 0.8313\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 466us/step - loss: 0.4139 - accuracy: 0.8317\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 462us/step - loss: 0.4126 - accuracy: 0.8328\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 457us/step - loss: 0.4118 - accuracy: 0.8326\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 470us/step - loss: 0.4110 - accuracy: 0.8338\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 452us/step - loss: 0.4101 - accuracy: 0.8345\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 463us/step - loss: 0.4096 - accuracy: 0.8344\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 444us/step - loss: 0.4085 - accuracy: 0.8335\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 442us/step - loss: 0.4081 - accuracy: 0.8326\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 442us/step - loss: 0.4076 - accuracy: 0.8340\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 462us/step - loss: 0.4068 - accuracy: 0.8344\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 463us/step - loss: 0.4064 - accuracy: 0.8354\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 450us/step - loss: 0.4065 - accuracy: 0.8347\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 439us/step - loss: 0.4058 - accuracy: 0.8346\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 473us/step - loss: 0.4054 - accuracy: 0.8351\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 466us/step - loss: 0.4047 - accuracy: 0.8339\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 457us/step - loss: 0.4053 - accuracy: 0.8341\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 466us/step - loss: 0.4044 - accuracy: 0.8364\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 466us/step - loss: 0.4041 - accuracy: 0.8340\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 474us/step - loss: 0.4043 - accuracy: 0.8360\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 456us/step - loss: 0.4030 - accuracy: 0.8353\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 462us/step - loss: 0.4035 - accuracy: 0.8360\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 446us/step - loss: 0.4033 - accuracy: 0.8365\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 453us/step - loss: 0.4034 - accuracy: 0.8356\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 456us/step - loss: 0.4030 - accuracy: 0.8346\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 472us/step - loss: 0.4031 - accuracy: 0.8360\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 457us/step - loss: 0.4028 - accuracy: 0.8349\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 449us/step - loss: 0.4031 - accuracy: 0.8349\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 481us/step - loss: 0.4028 - accuracy: 0.8369\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 508us/step - loss: 0.4026 - accuracy: 0.8363\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 452us/step - loss: 0.4027 - accuracy: 0.8350\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 458us/step - loss: 0.4027 - accuracy: 0.8356\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 439us/step - loss: 0.4025 - accuracy: 0.8359\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 461us/step - loss: 0.4027 - accuracy: 0.8351\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 458us/step - loss: 0.4020 - accuracy: 0.8340\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 471us/step - loss: 0.4019 - accuracy: 0.8345\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 461us/step - loss: 0.4021 - accuracy: 0.8350\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 466us/step - loss: 0.4023 - accuracy: 0.8346\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 467us/step - loss: 0.4018 - accuracy: 0.8339\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 457us/step - loss: 0.4022 - accuracy: 0.8353\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 474us/step - loss: 0.4025 - accuracy: 0.8355\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 468us/step - loss: 0.4017 - accuracy: 0.8357\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 438us/step - loss: 0.4021 - accuracy: 0.8353\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 445us/step - loss: 0.4022 - accuracy: 0.8357\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 469us/step - loss: 0.4018 - accuracy: 0.8353\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 452us/step - loss: 0.4016 - accuracy: 0.8361\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 462us/step - loss: 0.4019 - accuracy: 0.8346\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 457us/step - loss: 0.4020 - accuracy: 0.8357\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 0s 450us/step - loss: 0.4016 - accuracy: 0.8350\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 439us/step - loss: 0.4018 - accuracy: 0.8361\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 437us/step - loss: 0.4018 - accuracy: 0.8344\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 450us/step - loss: 0.4015 - accuracy: 0.8357\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 436us/step - loss: 0.4022 - accuracy: 0.8346\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 443us/step - loss: 0.4016 - accuracy: 0.8350\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 454us/step - loss: 0.4015 - accuracy: 0.8351\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 450us/step - loss: 0.4007 - accuracy: 0.8359\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 454us/step - loss: 0.4014 - accuracy: 0.8355\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 464us/step - loss: 0.4019 - accuracy: 0.8355\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 454us/step - loss: 0.4015 - accuracy: 0.8350\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 456us/step - loss: 0.4018 - accuracy: 0.8361\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 450us/step - loss: 0.4019 - accuracy: 0.8349\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 453us/step - loss: 0.4012 - accuracy: 0.8360\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 448us/step - loss: 0.4014 - accuracy: 0.8357\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 447us/step - loss: 0.4014 - accuracy: 0.8363\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 456us/step - loss: 0.4017 - accuracy: 0.8364\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 453us/step - loss: 0.4011 - accuracy: 0.8339\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 454us/step - loss: 0.4013 - accuracy: 0.8361\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 445us/step - loss: 0.4013 - accuracy: 0.8347\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 455us/step - loss: 0.4017 - accuracy: 0.8345\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 445us/step - loss: 0.4013 - accuracy: 0.8359\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 447us/step - loss: 0.4010 - accuracy: 0.8359\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 448us/step - loss: 0.4015 - accuracy: 0.8341\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 444us/step - loss: 0.4012 - accuracy: 0.8351\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 450us/step - loss: 0.4014 - accuracy: 0.8351\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 432us/step - loss: 0.4012 - accuracy: 0.8335\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 433us/step - loss: 0.4014 - accuracy: 0.8359\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 435us/step - loss: 0.4011 - accuracy: 0.8366\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 440us/step - loss: 0.4015 - accuracy: 0.8351\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 456us/step - loss: 0.4013 - accuracy: 0.8349\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 459us/step - loss: 0.4011 - accuracy: 0.8365\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 441us/step - loss: 0.4011 - accuracy: 0.8350\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 447us/step - loss: 0.4010 - accuracy: 0.8332\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 450us/step - loss: 0.4016 - accuracy: 0.8354\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 461us/step - loss: 0.4012 - accuracy: 0.8336\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 453us/step - loss: 0.4010 - accuracy: 0.8350\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 445us/step - loss: 0.4016 - accuracy: 0.8351\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 433us/step - loss: 0.4012 - accuracy: 0.8346\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 448us/step - loss: 0.4008 - accuracy: 0.8357\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 455us/step - loss: 0.4010 - accuracy: 0.8338\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 451us/step - loss: 0.4009 - accuracy: 0.8344\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 464us/step - loss: 0.4011 - accuracy: 0.8335\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 449us/step - loss: 0.4007 - accuracy: 0.8334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x22ddc956c10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building the ANN structure\n",
    "#Initializing the ANN:\n",
    "model = Sequential()\n",
    "\n",
    "#Adding the input layer and the first hidden layer, uniform distribution of the randomisation of our weights\n",
    "model.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 10))\n",
    "#Second hidden layer:\n",
    "model.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "#Adding the output layer\n",
    "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "#Compiling the ANN\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "#since our output is binary, we use binary_crossentropy loss function and accuracy metric\n",
    "\n",
    "#Train the ANN: fit the ANN to the Training Set\n",
    "model.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c15d1426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 371us/step\n",
      "            0\n",
      "count    2000\n",
      "unique      2\n",
      "top     False\n",
      "freq     1834\n",
      "63/63 [==============================] - 0s 427us/step - loss: 0.3983 - accuracy: 0.8395\n",
      "accuracy: 83.950001%\n"
     ]
    }
   ],
   "source": [
    "#Using our model to predict out of sample results:\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5) #means yes the customer did leave\n",
    "y_pred = pd.DataFrame(y_pred) #convert this scores to a dataset\n",
    "print(y_pred.describe()) #showing the prediction rows\n",
    "\n",
    "scores = model.evaluate(X_test, y_test) #get the scores of the sample space\n",
    "print(\"%s: %2f%%\" % (model.metrics_names[1], scores[1]*100)) \n",
    "#we had a 84% accuracy that is in line with our in sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f606b229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted No Exit</th>\n",
       "      <th>Predicted Exit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual No Exit</th>\n",
       "      <td>1554</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Exit</th>\n",
       "      <td>280</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted No Exit  Predicted Exit\n",
       "Actual No Exit               1554              41\n",
       "Actual Exit                   280             125"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one thing we can do with a binary classification problem is to make the confusion matrix to represent the data\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df = pd.DataFrame(cm)\n",
    "df.columns = ['Predicted No Exit', 'Predicted Exit']\n",
    "df.index = ['Actual No Exit', 'Actual Exit']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b54d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supervised Learning, implementation of Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the number of splits for cross-validation\n",
    "n_splits = 5  # You can adjust this number based on your needs\n",
    "\n",
    "# Create a KFold object\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,Y)\n",
    "\n",
    "#we use RSS (sum of squared residuals) as our loss function \n",
    "#parameters that minimize loss - line of best fit\n",
    "#grid search - to create a grid of all possible hyperparamter combinations and train the model using each of them\n",
    "# create a model object and define a dictionary where keys are hyperparameters and values are list of parameters\n",
    "    # - for linear regression this is a fit_intercept - yes/no\n",
    "param_grid = {'fit_intercept': [True,False]}\n",
    "\n",
    "#we use GridSearchCV object and provide:\n",
    "# the estimator object\n",
    "# paramter grid\n",
    "# scoring method\n",
    "# cross validation choice\n",
    "\n",
    "# Cross validation is a resampling procedure used to evaluate machine learning models, \n",
    "# and scoring paranter is the evaluation metrics of the model\n",
    "\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, scoring = 'r2', cv = kfold)\n",
    "grid_result = grid.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59184a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The above may lead to overfitting, so we introduce L1 and L2 regualizers to prevent overftting\n",
    "\n",
    "#Now the cost function = RSS + linear sum of all values of coefficients \n",
    "\n",
    "from sklearn.linear_model import Lasso #L1\n",
    "model = Lasso()\n",
    "model.fit(X,Y)\n",
    "\n",
    "from sklearn.linear_model import Ridge #L2\n",
    "model = Ridge() \n",
    "model.fit(X,Y)\n",
    "\n",
    "# The combination of both L1 and L2 is called the Elastric Net\n",
    "from sklearn.linear_model import ElasticNet\n",
    "model = ElasticNet()\n",
    "model.fit(X,Y) #on top of lamda variable for the L1 and L2 function, we also use alpha where alpha = 0 corresponds to L2\n",
    "#alpha = 1 corresponds to lasso\n",
    "\n",
    "#effectively it is the best of both worlds, this will shrink some coefficients and set some to 0 for sparse selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d372fd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "#Logistic Regression model arises from the desire to model the probabilities of the output classes given\n",
    "#a fucntion that is linear in X, at the same time ensuring that output probabilities sum up to 1 and remain between\n",
    "# 0 and 1, this is applied through the signmoid function\n",
    "\n",
    "# An example would to use Maximum likelihood estimation (MLE) to predict values close to 1 for the default class and\n",
    "# zero for other classes\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d16cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines, SVM, maxmises the margin, or the distrance between separating hyperplane / decision boundaries\n",
    "# and the training samples closest to this hyperplane (support vectors)\n",
    "\n",
    "# The margin is calculated as the perpendicular distance from the line to only the closest points, and therefore SVM\n",
    "# calculates a maximum-margin boundary that achieves complete partition of all data points\n",
    "\n",
    "# As data is always messy, we use a tuning paramter called C, the larger C is, the more violations of the hyperplane are\n",
    "# permitted\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "model.fit(X,Y)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(X,Y)\n",
    "\n",
    "# The hyperparamters are kernels (increasing the inputs to higher dimensions to ensure good fitting) and penalty, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d78d0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Means Clustering is an unsupervised machine learning algorithm used for clustering \n",
    "# or grouping data points into clusters based on their similarity. Its primary objectives are:\n",
    "\n",
    "# Objective:\n",
    "\n",
    "# Group Similar Data: K-Means aims to partition a dataset into clusters in such a way that data points \n",
    "# within the same cluster are more similar to each other than to data points in other clusters. \n",
    "# It tries to find the underlying structure or patterns in the data.\n",
    "\n",
    "# How It Works:\n",
    "\n",
    "# Initialization: The algorithm starts by randomly selecting K initial cluster centroids. \n",
    "# These centroids are typically data points from the dataset or generated randomly.\n",
    "\n",
    "# Assignment: Each data point is assigned to the nearest centroid based on a distance metric, often Euclidean distance. \n",
    "# This step forms initial clusters.\n",
    "\n",
    "# Update Centroids: For each cluster, the centroid is updated by calculating the mean (average) \n",
    "# of all data points assigned to that cluster. These updated centroids represent the \"center\" of the current clusters.\n",
    "\n",
    "# Repeat: Steps 2 and 3 are repeated iteratively until one of the stopping conditions is met. \n",
    "# Common stopping conditions include a maximum number of iterations or until centroids no longer change significantly.\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(X,Y)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X,Y)\n",
    "# The hyperparamters are no. of neighbors and distance metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e93931f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble Models - to combine different classifiers into a meta-classifier that has better generealization performance \n",
    "# than each individual classifier alone\n",
    "\n",
    "# The two most popular ensemble methods are bagging and boosting:\n",
    "\n",
    "# Bagging or Bootstrap Aggregation is an ensemble technique of training individual models in a parallel way. Each Model\n",
    "# is trained by a random subset of the data\n",
    "\n",
    "# Boosting, trains several individual model in a sequential way. This is done by building a model from the training data\n",
    "# and then creating a second model that attempts to correct the errors of the first model. Models are added until the\n",
    "# training set is predicted perfectly or a maximum number of models is added\n",
    "\n",
    "\n",
    "# By combining individual models, the ensemble model tends to be more flexible (less bias) and less data-sensitive / lower\n",
    "# variance. Ensemble models combine multiple, simpler algorithms to obtain better performance \n",
    "\n",
    "\n",
    "# What are some methods? \n",
    "# 1. Random Forest - a tweaked version of bagged decision trees\n",
    "\n",
    "# steps for bagging\n",
    "# 1. Create many random subsamples of our dataset\n",
    "# 2. Train a CART model on each sample\n",
    "# 3. Given a new dataset, calculate the average prediction from each model and aggregate the prediction by each tree to  \n",
    "# assign the final label by majority vote \n",
    "\n",
    "# One problem with decision trees like CART is that they are greedy - they choose the variable to split by using a greedy \n",
    "# algorithm that minimzies error\n",
    "\n",
    "# Another problem is that even after bagging, the decision trees can have a lot of structural similarities and result in\n",
    "# high correlation in their prediction. It would work better if predictions from the submodels ar uncorrelated or at \n",
    "# best lowly correlated \n",
    "\n",
    "# In CART, when selecting a split point, the learning algorithm is allowed to look through all variables and all variables\n",
    "# values in order to select the most optimal split point\n",
    "\n",
    "# The random forest algorithm changes this procedure such that each subtree can access only a random sample of features \n",
    "# when selecting a split point\n",
    "\n",
    "# Regression:\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X,Y)\n",
    "\n",
    "# Classification:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X,Y)\n",
    "# hyperparameters are max no. of features and no. of estimators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21b076f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaptive Boosting (Adaboost)\n",
    "# This is a boosting technique in which the basic idea to to try predictors sequentially, and each subsequent model\n",
    "# attempts to fix the errors of its predecessor. At each iteration, the AdaBoost algorithm changes the sample distribution\n",
    "# by modifying the weights attached to each of the instances \n",
    "    # - It increases the weights of the wrongly predicted instances and decreases the ones of the correctly \n",
    "    #   predicted instances \n",
    "#Steps:\n",
    "    # 1. Initially, all observations are given equal weights \n",
    "    # 2. A model is built on a subset of data, and the predictions are made on the whole dataset. Errors are calculated. \n",
    "    # 3. While creating the next model, higher weights are given the wrongly predicted instances and decreases \n",
    "    #    the ones of the correctly predicted instances\n",
    "    # 4. This process is repeated until the error function does not change, or until the maximum limit of the number of \n",
    "    #    estimators is reached\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor()\n",
    "model.fit(X,Y)\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier()\n",
    "model.fit(X,Y)\n",
    "# hyperparamters are Learning rate and number of estimators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba587bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Method works by sequentially adding the previous underfitted predictions to the ensemble,\n",
    "# ensuring the errors made previously are corrected \n",
    "\n",
    "# The objective is to find the best split in the data to minimize the error\n",
    "# Steps:\n",
    "    # 1. A model is built on a subset of data. Using this model, predictions are made on the whole of the dataset\n",
    "    # 2. Errors are calculated and the loss function is used\n",
    "    # 3. A new model is created using the errors of the previous step as the target varaible. The predictions made by \n",
    "    #    this new model are combined with the predictions of the previous.\n",
    "    # 4. This process is repeated until the error fucntion does not change or until the maximum limit of the number\n",
    "    #     of the number of estimators is reached\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X,Y)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X,Y)\n",
    "# hyperparamters are same as AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cbc3038c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For neural networks, \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "model = MLPRegressor()\n",
    "model.fit(X,Y)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier()\n",
    "model.fit(X,Y)\n",
    "# hyperparamters are hidden layers and activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of Time Series Models: \n",
    "#     A time series is a sequence of numbers that are ordered by a time index\n",
    "# A time series can be broken down into the following componenets:\n",
    "#     1. Trend Component\n",
    "#         - Consistent directional movement in a time series where it can be deterministic / stochastic\n",
    "#     2. Seasonal Component\n",
    "#         - Many time series contain seasonal variation like business cycles / climate data\n",
    "#         - This is particularly true regarding commodity prices such as natural gas with depends on annual temperature\n",
    "# This can be written as Y = S + T + R (S - seasonality, T - trend, R - error / remainder that is not captured)\n",
    "\n",
    "# Autocorrelation\n",
    "#     - It is the similarity between observations as a function of the time lag between them \n",
    "# Such relationships can be modeled using an autoregression model - regression of the variable against itself\n",
    "# In an autoregression model, we forecast the variable of interest using a linear combination of past values of the variable\n",
    "\n",
    "# Stationary \n",
    "#     - A time series is said to be stationary if its statistical properties do not change over time. \n",
    "#     - Thus a time series with trend or with seasonality is not stationary, as the trend and seasonality will affect\n",
    "#       the value of the time series at different times \n",
    "#     - On the other hand, a white noise series is stationary, as it does not matter when you observe it; it should look \n",
    "#       similar at anyt point in time \n",
    "#     - Predicting future values using a stationary plot would be easier and most statistical models require the series\n",
    "#       to be stationary to make it effective and precise predictions -> convert any non-stationary data to stationary\n",
    "#     - Thus we use differencing to remove its series dependence on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72d0b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional Time Series Model (Including the ARIMA Model):\n",
    "#     Most of the time series models aim at incorporating the trend, seasonality, and remainder components while addressing\n",
    "#     the autocorrelation and stationarity embedded in the time series\n",
    "    \n",
    "#     For instance, the autoregressive (AR) model address the autocorrelation in the time series\n",
    "    \n",
    "# ARIMA:\n",
    "#     If we combine stationarity with autoregression and a moving average model, \n",
    "#     we obtain a ARIMA Model (Autoregressive Integrated Moving Average\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Specify the order of the ARIMA model (p, d, q)\n",
    "# You need to provide the appropriate values for p, d, and q\n",
    "# For example, order=(1, 0, 0) corresponds to an AR(1) model\n",
    "model = ARIMA(y_train, order=(1, 0, 0))\n",
    "\n",
    "# Fit the ARIMA model to your training data\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Make predictions using the fitted model\n",
    "y_pred = model_fit.forecast(steps=len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90893da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert a time series model to our supervised machine learning model:\n",
    "#     we would offset the data - by using a previous timestep to input and the next timestep as output into our model\n",
    "#     this can be done using the shift function in pandas, resembling something like a sliding window\n",
    "#     we'll delete the first and last row as it does not contain any data in terms of X and Y\n",
    "#      from here we will continue with the notebook 'Regression-Master Template'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
